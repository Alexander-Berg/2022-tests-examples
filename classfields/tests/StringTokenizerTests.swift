//
//  StringTokenizerTests.swift
//  YRECoreUtils-Unit-Tests
//
//  Created by Alexey Salangin on 21.05.2021.
//  Copyright ¬© 2021 Yandex. All rights reserved.
//

import Foundation
import YRECoreUtils
import XCTest

final class StringTokenizerTests: XCTestCase {
    func testTokenizeByWords() {
        let sentence = "–í—Å–µ ü§¨, –∞ —è ‚Äî –∫–∞–ø–∏—Ç–∞–Ω-–ª–µ–π—Ç–µ–Ω–∞–Ω—Ç –¥‚Äô–ê—Ä—Ç–∞–Ω—å—è–Ω"
        let expectedWordsWithRanges = [
            ("–í—Å–µ", NSRange(location: 0, length: 3)),
            ("ü§¨", NSRange(location: 4, length: 2)),
            ("–∞", NSRange(location: 8, length: 1)),
            ("—è", NSRange(location: 10, length: 1)),
            ("–∫–∞–ø–∏—Ç–∞–Ω-–ª–µ–π—Ç–µ–Ω–∞–Ω—Ç", NSRange(location: 14, length: 17)),
            ("–¥‚Äô–ê—Ä—Ç–∞–Ω—å—è–Ω", NSRange(location: 32, length: 10)),
        ]

        let result = sentence.yre_tokenizeByWords()
        zip(result, expectedWordsWithRanges).forEach {
            XCTAssertEqual($0.0, $1.0)
            XCTAssertEqual($0.1, $1.1)
        }
    }

    func testTokenizeByWordsWithRepeatedWords() {
        let sentence = """
        –°–æ–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤—ã—Å—à–µ–≥–æ –ø–æ—Ä—è–¥–∫–∞, –∞ —Ç–∞–∫–∂–µ —Å–æ—Ü–∏–∞–ª—å–Ω–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —à–∏—Ä–æ–∫–æ–º—É –∫—Ä—É–≥—É \
        —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤ —É—á–∞—Å—Ç–∏–µ –≤ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π.
        """
        let expectedWordsWithRanges = [
            ("–°–æ–æ–±—Ä–∞–∂–µ–Ω–∏—è", NSRange(location: 0, length: 11)),
            ("–≤—ã—Å—à–µ–≥–æ", NSRange(location: 12, length: 7)),
            ("–ø–æ—Ä—è–¥–∫–∞", NSRange(location: 20, length: 7)),
            ("–∞", NSRange(location: 29, length: 1)),
            ("—Ç–∞–∫–∂–µ", NSRange(location: 31, length: 5)),
            ("—Å–æ—Ü–∏–∞–ª—å–Ω–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–µ", NSRange(location: 37, length: 23)),
            ("—Ä–∞–∑–≤–∏—Ç–∏–µ", NSRange(location: 61, length: 8)),
            ("–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç", NSRange(location: 70, length: 12)),
            ("—à–∏—Ä–æ–∫–æ–º—É", NSRange(location: 83, length: 8)),
            ("–∫—Ä—É–≥—É", NSRange(location: 92, length: 5)),
            ("—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤", NSRange(location: 98, length: 12)),
            ("—É—á–∞—Å—Ç–∏–µ", NSRange(location: 111, length: 7)),
            ("–≤", NSRange(location: 119, length: 1)),
            ("—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏", NSRange(location: 121, length: 12)),
            ("—Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö", NSRange(location: 134, length: 12)),
            ("—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö", NSRange(location: 147, length: 10)),
            ("–∏", NSRange(location: 158, length: 1)),
            ("–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã—Ö", NSRange(location: 160, length: 16)),
            ("—É—Å–ª–æ–≤–∏–π", NSRange(location: 177, length: 7)),
        ]

        let result = sentence.yre_tokenizeByWords()
        zip(result, expectedWordsWithRanges).forEach {
            XCTAssertEqual($0.0, $1.0)
            XCTAssertEqual($0.1, $1.1)
        }
    }
}
