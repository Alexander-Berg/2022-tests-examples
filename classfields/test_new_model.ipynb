{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../price-estimator-rest-api/scripts/')\n",
    "import quadkey\n",
    "sys.path.append('../../price-estimator-rest-api/proto.out')\n",
    "\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from config import *\n",
    "from realty.prediction import price_prediction_pb2\n",
    "from realty.offer import common_pb2\n",
    "from time import time\n",
    "from joblib import delayed, Parallel\n",
    "from tqdm import tqdm_notebook\n",
    "import requests\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import datetime\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "## vkokhtev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers = pd.read_csv('./rooms.tsv', sep='\\t', error_bad_lines=False)\n",
    "offers['is_apartment'] = offers['is_apartment'].fillna(False)\n",
    "offers['kitchen_area'] = offers['kitchen_area'].fillna(0)\n",
    "offers['living_area'] = offers['living_area'].fillna(0)\n",
    "offers['renovation'] = offers['renovation'].fillna(0)\n",
    "offers['balcony'] = offers['balcony'].fillna(0)\n",
    "offers['parking'] = offers['parking'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def address_to_locality(string):\n",
    "#     try:\n",
    "#         r = requests.get('http://geocode-net.datatesting.int01e.tst.maps.yandex.ru/1.x/?format=json&geocode={}&results=1'.format(string))\n",
    "#         obj = r.json()['response']['GeoObjectCollection']['featureMember'][0]['GeoObject']['metaDataProperty']['GeocoderMetaData']\n",
    "#     except:\n",
    "#         obj = dict({'text':'geocode_error'})\n",
    "#     try:\n",
    "#         coord = obj['InternalToponymInfo']['Point']['pos']\n",
    "#     except:\n",
    "#         coord = '0 0'\n",
    "#     try:\n",
    "#         locality_name = obj['AddressDetails']['Country']['AdministrativeArea']['SubAdministrativeArea']['Locality']['LocalityName']\n",
    "#     except:\n",
    "#         try:\n",
    "#             locality_name = obj['AddressDetails']['Country']['AdministrativeArea']['Locality']['LocalityName']\n",
    "#         except:\n",
    "#             locality_name = 'geocode_error'\n",
    "#     try:\n",
    "#         region = obj['AddressDetails']['Country']['AdministrativeArea']['AdministrativeAreaName']\n",
    "#     except:\n",
    "#         region = 'geocode_error'\n",
    "#     if obj['text'] == string:\n",
    "#         return [string, region, locality_name, coord]\n",
    "#     else:\n",
    "#         return [obj['text'], region, locality_name, coord]\n",
    "\n",
    "# def choose_address(geo_adr, db_adr):\n",
    "#     count = 0\n",
    "#     if (geo_adr == db_adr) | ('ё' in (geo_adr + db_adr)):\n",
    "#         return [geo_adr, count]\n",
    "#     if (\"ЖК\" in db_adr) | ('geocode_error' in geo_adr) | (len(geo_adr.split(',')) < 2):\n",
    "#         return [db_adr, count]\n",
    "#     geo_pred = ' '.join(geo_adr.split(' ')[:-1])\n",
    "#     db_pred = ' '.join(db_adr.split(' ')[:-1])\n",
    "#     if geo_pred == db_pred:\n",
    "#         count += 1\n",
    "#         return [geo_adr, count]\n",
    "#     return [geo_adr, count]\n",
    "\n",
    "# offers_addess_pd = pd.unique(offers['unified_address'])\n",
    "\n",
    "# offers_addresses = Parallel(n_jobs=40, verbose=0)(delayed(address_to_locality)(address) for address in tqdm_notebook(offers_addess_pd))\n",
    "\n",
    "# offers_addr = pd.DataFrame(offers_addresses, columns=['geocoder_address','region','locality_name', 'coords'])\n",
    "# offers_addr['offers_address'] = offers_addess_pd\n",
    "\n",
    "# offers_addr['correct_address'], offers_addr['count'] = '', 0\n",
    "# offers_addr['correct_address'], offers_addr['count'] = map(list, zip(*([choose_address(geo_adr, db_adr) for geo_adr, db_adr \\\n",
    "#                                 in tqdm_notebook(zip(offers_addr['geocoder_address'],offers_addr['offers_address']))])))\n",
    "# dubl_offers = offers_addr[offers_addr['count'] == 1]\n",
    "# dubl_offers['correct_address'] = dubl_offers['offers_address']\n",
    "# offers_addr['count'] = 0\n",
    "# offers_addr = pd.concat([offers_addr,dubl_offers], axis=0)\n",
    "# for col in ['geocoder_address', 'offers_address', 'correct_address']:\n",
    "#     offers_addr[col] = offers_addr[col].apply(lambda x: x.split(', подъезд')[0])\n",
    "\n",
    "# offers_addr.to_csv('./offers_addr_loc_names_coords.tsv',sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quadkeys(lat, lon):\n",
    "    city_quadkey = quadkey.latlon2quadkey(lat, lon, zoom=15)\n",
    "    region_quadkey = city_quadkey[:10]\n",
    "    return city_quadkey, region_quadkey\n",
    "\n",
    "def error_percentage(y_test, y_pred):\n",
    "    return sum((np.divide(y_pred,y_test) - 1).apply(abs) < 0.15) / y_pred.shape[0]\n",
    "\n",
    "def mean_absolute_percentage_error(y_test, y_pred): \n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "offers_addr = pd.read_csv('./offers_addr_loc_names_coords.tsv',sep='\\t')\n",
    "cols = offers.columns\n",
    "\n",
    "offers = pd.merge(offers, offers_addr, left_on='unified_address', right_on='offers_address')\n",
    "\n",
    "adr_mask = (offers['correct_address'] != 'geocode_error')\n",
    "sf_mask = (offers['subject_federation_id'].notnull())\n",
    "offers = offers[adr_mask & sf_mask]\n",
    "offers.rename(columns={'locality_name_y':'locality_name'}, inplace=True)\n",
    "offers = offers[list(cols) + ['region', 'coords', 'correct_address']]\n",
    "offers.drop(['unified_address','total_area', \n",
    "             'subject_federation_id', 'locality_name', 'region'], axis=1, inplace=True)\n",
    "\n",
    "housebase = pd.read_csv('../../data/database/data/housebase_improved_all.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(offers, housebase, how='inner', on='correct_address')\n",
    "df['first_day_exposition'] = pd.to_datetime(df['first_day_exposition'])\n",
    "df = df.sort_values('first_day_exposition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModelContainer:\n",
    "    def __init__(self, model_path, factors):\n",
    "        self.model = CatBoostRegressor().load_model(model_path, format='catboost')\n",
    "        self.factors = factors\n",
    "\n",
    "    def predict(self, df):\n",
    "        start_time = time()\n",
    "        X = df[self.factors]\n",
    "        result = np.power(self.model.predict(X), 3)\n",
    "\n",
    "        end_time = time()\n",
    "        logging.info('predicted value: ' + str(result))\n",
    "        logging.info('predict time: ' + str(end_time - start_time))\n",
    "\n",
    "        return result\n",
    "\n",
    "class PricePredictor:\n",
    "    def __init__(self):\n",
    "        prefix = './../../price-estimator-rest-api/model/'\n",
    "        self.msk_mo_rent_model = PredictionModelContainer(\n",
    "            prefix+MSK_MO_RENT_MODEL_PATH, MSK_MO_RENT_FACTORS)\n",
    "        self.msk_mo_sell_model = PredictionModelContainer(\n",
    "            prefix+MSK_MO_SELL_MODEL_PATH, MSK_MO_SELL_FACTORS)\n",
    "        self.spb_lo_rent_model = PredictionModelContainer(\n",
    "            prefix+SPB_LO_RENT_MODEL_PATH, SPB_LO_RENT_FACTORS)\n",
    "        self.spb_lo_sell_model = PredictionModelContainer(\n",
    "            prefix+SPB_LO_SELL_MODEL_PATH, SPB_LO_SELL_FACTORS)\n",
    "        self.regions_rent_model = PredictionModelContainer(\n",
    "            prefix+REGIONS_RENT_MODEL_PATH, REGIONS_RENT_FACTORS)\n",
    "        self.regions_sell_model = PredictionModelContainer(\n",
    "            prefix+REGIONS_SELL_MODEL_PATH, REGIONS_SELL_FACTORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 SELL 24.804450752993233 0.370595382746051\n",
      "1 RENT 17.269170455309947 0.5454895913646878\n",
      "10174 SELL 25.065290469053696 0.3574010654490107\n",
      "10174 RENT 16.122629330314314 0.5509945877556758\n",
      "0 SELL 24.15689935140137 0.3756166653819471\n",
      "0 RENT 25.906599866501367 0.3599845286772019\n"
     ]
    }
   ],
   "source": [
    "price_pred = PricePredictor()\n",
    "\n",
    "pred_dict = dict()\n",
    "\n",
    "for s_f_id in [1, 10174, 0]:\n",
    "    for off_t in [1, 2]:\n",
    "        subject_federation_id = s_f_id\n",
    "        offer_type = common_pb2.OfferType.Name(off_t)\n",
    "        if subject_federation_id == MSK_MO_SUBJECT_FEDERATION_ID:\n",
    "            if offer_type == RENT:\n",
    "                model = price_pred.msk_mo_rent_model\n",
    "            elif offer_type == SELL:\n",
    "                model = price_pred.msk_mo_sell_model\n",
    "\n",
    "        elif subject_federation_id == PITER_LO_SUBJECT_FEDERATION_ID:\n",
    "            if offer_type == RENT:\n",
    "                model = price_pred.spb_lo_rent_model\n",
    "            elif offer_type == SELL:\n",
    "                model = price_pred.spb_lo_sell_model\n",
    "\n",
    "        elif subject_federation_id != MSK_MO_SUBJECT_FEDERATION_ID \\\n",
    "                and subject_federation_id != PITER_LO_SUBJECT_FEDERATION_ID:\n",
    "            if offer_type == RENT:\n",
    "                model = price_pred.regions_rent_model\n",
    "            elif offer_type == SELL:\n",
    "                model = price_pred.regions_sell_model\n",
    "        \n",
    "        mask = df['year'] > -1\n",
    "        mask = mask & (df['offer_type'] == off_t)\n",
    "        if s_f_id == 0:\n",
    "            mask = mask & (df['subject_federation_id'] != 1) \\\n",
    "                        & (df['subject_federation_id'] != 10174) \n",
    "        else:\n",
    "            mask = mask & (df['subject_federation_id'] == s_f_id)\n",
    "        \n",
    "        X = df[mask]\n",
    "        \n",
    "        y_test = X['last_price']\n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        values = [mean_absolute_percentage_error(y_test, y_pred*alpha) for alpha in np.linspace(0,1,10000)]\n",
    "    \n",
    "        print(s_f_id, offer_type, min(values), error_percentage(y_test, y_pred*np.argmin(values)/10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_data(X, y, time_column, time):\n",
    "    X_train = X[X[time_column] < time]\n",
    "    X_test = X[X[time_column] >= time]\n",
    "    y_train, y_test = y.loc[X_train.index], y.loc[X_test.index]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "split_date_test = pd.to_datetime('05.05.2018')\n",
    "split_date_val = pd.to_datetime('09.05.2018')\n",
    "\n",
    "def down_iter(size):\n",
    "    if size == 1:\n",
    "        return [1]\n",
    "    if size == 2:\n",
    "        return [0.5,0.5]\n",
    "    prev_arr = down_iter(size-1)[:-1]\n",
    "    next_value = (1 - sum(prev_arr)) / 2\n",
    "    return prev_arr + [next_value] * 2\n",
    "\n",
    "def train_catboost(model, X_train, y_train, X_test, y_test, cat_features, lr_down_rate=5):\n",
    "    iterations = model.get_params()['iterations'] # 100\n",
    "    learning_rate = model.get_params()['learning_rate'] # 5\n",
    "    bounds = np.array(down_iter(lr_down_rate)) # 0.5   , 0.25  , 0.125 , 0.0625, 0.0625\n",
    "    lr_arr = [learning_rate / (1.9 ** i) for i in range(lr_down_rate)]# 5.0, 2.5, 1.25, 0.625, 0.3125\n",
    "    iter_arr = (bounds * iterations).astype(int) # 150,  75,  37,  18,  18\n",
    "    n_trees_count = 0\n",
    "    for n_trees, lr in zip(iter_arr, lr_arr):\n",
    "        n_trees_count += n_trees\n",
    "        print(n_trees, lr)\n",
    "        model.set_params(iterations=n_trees_count, learning_rate=lr)\n",
    "        model.fit(X_train, y_train, metric_period=300,\n",
    "                  early_stopping_rounds=1, cat_features=[i for i, c in enumerate(X_train) if c in cat_features])\n",
    "    return model\n",
    "\n",
    "def training_model(X, y, model_parameters, cat_columns):\n",
    "    X_train, y_train, X_test, y_test = splitting_data(X, y, 'first_day_exposition', split_date_test)\n",
    "    del X_train['first_day_exposition']\n",
    "    del X_test['first_day_exposition']\n",
    "    lr_count = model_parameters['lr_count']\n",
    "    del model_parameters['lr_count']\n",
    "    if lr_count == 1:\n",
    "        del model_parameters['save_snapshot']\n",
    "    \n",
    "    model = CatBoostRegressor(**model_parameters)\n",
    "    trained_model = train_catboost(model, X_train, y_train, X_test, y_test, cat_columns, lr_down_rate=lr_count)\n",
    "    y_pred = np.power(trained_model.predict(X_test), 3)\n",
    "    y_test = np.power(y_test, 3)\n",
    "    ep = error_percentage(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    print(mape)\n",
    "    return trained_model, ep, mape\n",
    "\n",
    "def pipeline(X, offer_type, sfId_arr, columns, cat_columns, model_parameters):\n",
    "    mask = (X['subject_federation_id'] == 0)\n",
    "    for i in sfId_arr:\n",
    "        mask = mask | (X['subject_federation_id'] == i)\n",
    "    pool = X[mask]\n",
    "    \n",
    "    pool = pool[pool['offer_type'] == offer_type]\n",
    "    target = np.cbrt(pool['last_price'])\n",
    "    pool = pool[columns]\n",
    "    pool_train, target_train, pool_val, target_val = splitting_data(pool, target,\\\n",
    "                                                                    'first_day_exposition', split_date_val)\n",
    "    del pool_val['first_day_exposition']\n",
    "    target_val = np.power(target_val, 3)\n",
    "    \n",
    "    results = []\n",
    "    mape_best = [100, 100, '']\n",
    "    ep_best = [0, 0, '']\n",
    "    \n",
    "    for params in tqdm_notebook(model_parameters):\n",
    "        model_name = '_'.join([str(s) for s in params.values()])\n",
    "        #return training_model(pool_train, target_train, params, cat_columns)\n",
    "        trained_model, ep, mape = training_model(pool_train, target_train, params, cat_columns)\n",
    "        try:\n",
    "            os.remove('./catboost_info/experiment.cbsnapshot')\n",
    "        except:\n",
    "            a = 0\n",
    "        \n",
    "        val_predict = np.power(trained_model.predict(pool_val), 3)\n",
    "        mape_val = mean_absolute_percentage_error(val_predict, target_val)\n",
    "        ep_val = error_percentage(val_predict, target_val)\n",
    "        \n",
    "        if mape <= mape_best[0]:\n",
    "            mape_best = [mape, mape_val, model_name]\n",
    "        \n",
    "        if ep >= ep_best[0]:\n",
    "            ep_best = [ep, ep_val, model_name]\n",
    "        \n",
    "        results.append([model_name, mape, mape_val, ep, ep_val])\n",
    "        \n",
    "    return results, ep_best, mape_best, trained_model\n",
    "\n",
    "param_grid_catboost_sell = ParameterGrid({'save_snapshot':[True],'lr_count': [1], 'learning_rate': [50, 100, 200],\\\n",
    "                                     'iterations': [1000], 'depth': [7],\\\n",
    "                                     'thread_count':[48], 'random_seed':[0],'border_count':[100],\\\n",
    "                                     'has_time':[True],'counter_calc_method':['SkipTest'],\\\n",
    "                                     'loss_function':['MAPE'],'logging_level':['Verbose']})\n",
    "\n",
    "param_grid_catboost_rent = ParameterGrid({'save_snapshot':[True],'lr_count': [1], 'learning_rate': [1, 3, 10, 20],\\\n",
    "                                     'iterations': [1000], 'depth': [4, 7, 9],\\\n",
    "                                     'thread_count':[48], 'random_seed':[0],'border_count':[100],\\\n",
    "                                     'has_time':[True],'counter_calc_method':['SkipTest'],\\\n",
    "                                     'loss_function':['MAPE'],'logging_level':['Silent']})\n",
    "\n",
    "\n",
    "def train(offer_type, name, subject_arr, columns, cat_columns):\n",
    "    start_time = time()\n",
    "    if offer_type == 1:\n",
    "        params = param_grid_catboost_sell\n",
    "    else:\n",
    "        params = param_grid_catboost_rent\n",
    "        \n",
    "    results, ep_best, mape_best, _ = pipeline(X, offer_type, subject_arr, columns, cat_columns, params)\n",
    "    results = pd.DataFrame(results, columns=['model_name','MAPE_test','MAPE_val','EP_test','EP_val'])\n",
    "    results.to_csv('./results_{}.tsv'.format(name), sep='\\t',index=None)\n",
    "    \n",
    "    end_time = time()\n",
    "    \n",
    "    print(str(datetime.timedelta(seconds=end_time-start_time)))\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79682aac71094bbabc41eeb5f846243d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1.0\n",
      "16.888883582431365\n",
      "1000 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.835884523267964\n",
      "1000 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.717888995871885\n",
      "1000 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.559446094840233\n",
      "1000 1.0\n",
      "16.741488623503802\n",
      "1000 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.711187965912472\n",
      "1000 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.76219806919209\n",
      "1000 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.44779057958254\n",
      "1000 1.0\n",
      "16.717177915931234\n",
      "1000 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.798432454399986\n",
      "1000 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.736726148694743\n",
      "1000 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.745902691509045\n",
      "0:08:19.077208\n"
     ]
    }
   ],
   "source": [
    "sfID = list(X['subject_federation_id'].unique())\n",
    "sfID.remove(1)\n",
    "sfID.remove(10174)\n",
    "\n",
    "columns_rent_reg = price_pred.regions_rent_model.factors + ['first_day_exposition']\n",
    "cat_columns_rent_reg = ['studio', 'is_apartment','rooms_offered',\n",
    "                        'renovation', 'balcony', 'series_name',\n",
    "                        'building_type_str', 'heatingType',\n",
    "                        'expectDemolition','subject_federation_id',\n",
    "                        'locality_name', 'city_quadkey','region_quadkey']\n",
    "\n",
    "code = train(2, 'rent_reg', sfID, columns_rent_reg, cat_columns_rent_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
